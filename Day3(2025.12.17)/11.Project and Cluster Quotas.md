# Chapter 6. Enable Developer Self-Service

## 6-1. Project and Cluster Quotas


### ResourceQuota, ClusterResourceQuota(openshift only) 란?

CPU, RAM, 스토리지와 같은 클러스터 자원은 제한되어있다.
그렇기 때문에 너무 많은 pod나 deployment를 생성하게 되면, CPU나 메모리를 너무 과도하게 사용하게 된다.

그러면 1) 다른 워크로드에 장애를 입히거나, 2) autoscaling 이 잦아져 운영 비용이 증가하거나 3) etcd 성능이 저하되게된다.   

그래서 ResourceQuota, ClusterResourceQuota 기능을 통해 자원의 사용을 제한하게된다.

둘의 차이는 어느 범주의 리소스를 제한할것이냐 하는 것인데,  

ResourceQuota 는 **"네임스페이스"** 단위로,   
ClusterResourceQuota는 **"여러 네임스페이스를 묶은 단위"**로 자원 사용 총량을 제한한다.   
이것은 Openshift 에서만 사용가능한 기능이다.   


### ResourceQuota 설정 파라미터

namespace 단위로 적용 가능하다.

1) compute resource quota

    ```code
    requests.cpu
    requests.memory
    limits.cpu
    limits.memory
    ```

2) object count quota

    namespace내부에 Pods, Deployments, Services, PVC 등의 리소스 갯수를 제한하는 것.
    Kubernetes는 모든 리소스를 etcd(DB)에 저장하는데, 오브젝트가 많아질수록 메모리 사용 증가하고 API 응답 느려진다. object 갯수를 제한하면 etcd 성능을 보호할 수 있다.

    ```code
    count/pods
    count/deployments.apps
    count/services
    ```

### ResourceQuota 설정 방법

1) ResourceQuota를 생성해서 아래와 같이 memory limit과 request를 설정하는 yaml 작성.

```yaml
## quota.yaml 파일

apiVersion: v1
kind: ResourceQuota
metadata:
  namespace: example
spec:
  hard:
    count/pods: "1"
    limits.memory: 4Gi
    requests.memory: 2Gi
```


위와 같이 설정하면, 해당 네임스페이스는 **"파드는 딱 1개만 띄울 수 있고, 그 파드의 메모리 제한 합계도 4Gi를 넘길 수 없다"**는 제약을 가지게 된다.


2) ResourceQuota 적용 명령어

```code
oc apply -f quota.yaml
```


3) ResourceQuota 확인 명령어

```code
oc describe resourcequota example
```

4) cli로도 설정할 수 있다.

```yaml
# compute resource quota
oc create resourcequota example --hard=limits.memory=4Gi,requests.memory=2Gi 

# object count quota
oc create resourcequota example --hard=count/pods=1
```

### ResourceQuota 설정 후 확인

```code
oc get quota example -o yaml

```
```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  creationTimestamp: "2024-01-30T17:59:52Z"
  name: example
  namespace: default
  resourceVersion: "193658"
  uid: df12b484-4e78-4920-acb4-e04ab286a4a1
spec:
  hard:
    count/pods: "1"
status:
  hard:
    count/pods: "1"
  used:
    count/pods: "0"
```

또는, 

```code
oc get quota
```

해당 명령어는 리소스 목록에 할당량 상태를 표시한다.


```code
NAME      AGE     REQUEST           LIMIT
example   9m54s   count/pods: 1/1
```


### Resource Request, Limit


#### Requests(최소 보장)

쿠버네티스 스케줄러는 노드의 "실제 사용량"이 아니라, **"이미 배치된 Pod들의 Requests 합계"**를 보고 여유 공간을 계산한다. 이때, 참고로 하는 값이 requests이다.  
최소 requests 설정 만큼의 값을 쓰겠다고 선점하는 것이기 때문에, 실제 Pod가 그만큼의 자원을 안 쓰더라도 다른 Pod가 그 자원을 사용할수는 없다.  


#### Limits (최대 한도)

Limits는 자원의 최대 사용가능 한도를 의미하는 값이다. 

이러한 사용한도는, 크게 **compute resource**와 **object count** 두 가지 부분에 대해서 설정가능하다.



#### CPU Limit 초과 시 

Pod가 죽지는 않지만, **Throttling(쓰로틀링)**이 발생한다.  
이때, CPU 속도를 강제로 낮춰서 limit이상 자원을 사용하지 못하도록 제한할 수 있다.  


##### Memory Limit 초과 시

메모리는 CPU처럼 속도를 줄일 수 없으므로, 커널이 **OOMKill(Out Of Memory Kill)**을 사용해서 해당 Pod을 즉시 종료시킨다.  


#### Quota 설정 후 필요한 설정

Quota을 설정하면 관리가 필요하므로, Request, Limit 가 없는 App은 아예 실행이 안된다.  
개별 App YAML에 **resources**를 적거나, 네임스페이스에 **LimitRange**를 설정해서 기본값을 부여해야한다.


1 . 개별 앱 yaml

```yaml
# 개별 앱 .yaml
spec:
  containers:
  - name: my-app
    image: nginx
    resources:  # <--- 이 부분이 반드시 포함되어야 함
      requests:
        memory: "1Gi"
        cpu: "500m"
      limits:
        memory: "2Gi"
        cpu: "1"
```

2-1. namespace 단위로 LimitRange 설정

```yaml
# limitrange 생성을 위한 limit-range.yaml 
apiVersion: v1
kind: LimitRange
metadata:
  name: default-limits
spec:
  limits:
  - default:          # limits가 없을 때 기본값
      cpu: "1"
      memory: "1Gi"
    defaultRequest:   # requests 가 없을 때 기본값
      cpu: "500m"
      memory: "512Mi"
    type: Container   # 컨테이너 단위로 적용
```

2-2. namespace에 설정 적용

```code
oc apply -f limit-range.yaml -n <네임스페이스명>
```


